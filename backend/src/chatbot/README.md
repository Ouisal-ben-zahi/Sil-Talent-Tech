# ğŸ¤– Chatbot IA avec RAG (Retrieval Augmented Generation)

## ğŸ“‹ Vue d'ensemble

Ce module implÃ©mente un chatbot IA professionnel utilisant la technique RAG pour rÃ©pondre aux utilisateurs uniquement Ã  partir des donnÃ©es internes stockÃ©es dans Supabase.

## ğŸ”§ Configuration

### Variables d'environnement requises

Ajoutez dans votre fichier `.env` du backend :

```env
# OpenAI API Key (requis pour les embeddings et la gÃ©nÃ©ration de texte)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Supabase (dÃ©jÃ  configurÃ©)
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key
```

### Installation des dÃ©pendances

Le module utilise dÃ©jÃ  les dÃ©pendances suivantes (dÃ©jÃ  installÃ©es) :
- `@supabase/supabase-js` - Pour accÃ©der Ã  Supabase
- `axios` - Pour les appels API OpenAI

## ğŸ—ï¸ Architecture

### Structure du module

```
chatbot/
â”œâ”€â”€ chatbot.module.ts      # Module NestJS
â”œâ”€â”€ chatbot.controller.ts  # ContrÃ´leur REST
â”œâ”€â”€ chatbot.service.ts     # Service RAG principal
â””â”€â”€ dto/
    â””â”€â”€ chat-message.dto.ts  # DTOs pour les requÃªtes/rÃ©ponses
```

### Flux de fonctionnement

1. **RÃ©ception de la requÃªte** : L'utilisateur envoie un message via l'API
2. **GÃ©nÃ©ration d'embedding** : Le message est converti en vecteur via OpenAI
3. **Recherche de documents** : Recherche dans Supabase (FAQs, articles, ressources, services)
4. **Construction du contexte** : Les documents pertinents sont assemblÃ©s
5. **GÃ©nÃ©ration de rÃ©ponse** : OpenAI gÃ©nÃ¨re une rÃ©ponse basÃ©e sur le contexte
6. **Retour de la rÃ©ponse** : La rÃ©ponse avec les sources est renvoyÃ©e

## ğŸ“Š Tables Supabase utilisÃ©es

Le chatbot recherche dans les tables suivantes :
- `faqs` - Questions frÃ©quentes
- `articles` - Articles de blog
- `ressources` - Ressources documentaires
- `services` - Services proposÃ©s

**Note** : Adaptez les noms de colonnes dans `chatbot.service.ts` selon votre schÃ©ma Supabase.

## ğŸš€ Utilisation

### Endpoint API

```
POST /chatbot/chat
```

**Body :**
```json
{
  "message": "Quels sont vos services en cybersÃ©curitÃ© ?",
  "conversationId": "conv-123" // Optionnel
}
```

**Response :**
```json
{
  "response": "Nous proposons plusieurs services en cybersÃ©curitÃ©...",
  "conversationId": "conv-123",
  "sources": [
    {
      "type": "service",
      "title": "CybersÃ©curitÃ©",
      "content": "Service: CybersÃ©curitÃ©\nDescription: ...",
      "relevance": 0.8
    }
  ],
  "tokensUsed": {
    "prompt": 500,
    "completion": 200,
    "total": 700
  }
}
```

## ğŸ”„ AmÃ©liorations futures

### Recherche vectorielle native

Pour une meilleure performance, implÃ©mentez une vraie recherche vectorielle :

1. **Stocker les embeddings** : CrÃ©ez une table `document_embeddings` dans Supabase
2. **Utiliser pgvector** : Activez l'extension pgvector dans Supabase
3. **Recherche par similaritÃ© cosinus** : Utilisez `<=>` pour la recherche vectorielle

Exemple de migration SQL :

```sql
-- Activer pgvector
CREATE EXTENSION IF NOT EXISTS vector;

-- CrÃ©er la table d'embeddings
CREATE TABLE document_embeddings (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  content TEXT NOT NULL,
  embedding vector(1536), -- Dimension pour text-embedding-3-small
  metadata JSONB,
  created_at TIMESTAMP DEFAULT NOW()
);

-- CrÃ©er un index pour la recherche vectorielle
CREATE INDEX ON document_embeddings USING ivfflat (embedding vector_cosine_ops);
```

### Indexation automatique

CrÃ©ez un service d'indexation qui :
- Parcourt automatiquement les tables Supabase
- GÃ©nÃ¨re les embeddings pour chaque document
- Les stocke dans `document_embeddings`

## ğŸ›¡ï¸ SÃ©curitÃ©

- L'endpoint est public (`@Public()`) mais peut Ãªtre protÃ©gÃ© si nÃ©cessaire
- Les clÃ©s API OpenAI doivent Ãªtre gardÃ©es secrÃ¨tes
- Limitez le taux de requÃªtes avec Throttler (dÃ©jÃ  configurÃ©)

## ğŸ“ Notes

- Le modÃ¨le utilisÃ© est `gpt-4-turbo-preview` (modifiable dans `chatbot.service.ts`)
- Le modÃ¨le d'embedding est `text-embedding-3-small`
- La tempÃ©rature est fixÃ©e Ã  0.7 pour un bon Ã©quilibre crÃ©ativitÃ©/prÃ©cision
- Les rÃ©ponses sont limitÃ©es Ã  500 tokens maximum





